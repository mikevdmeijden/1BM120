{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhI1eNEXQCjK"
   },
   "source": [
    "# KnapsackV2\n",
    "1BM120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9qH33L_QoBk"
   },
   "source": [
    "    Import the neccary packages\n",
    "- `Numpy` for our Qtable\n",
    "- `OpenAI Gym` for our FrozenLake Environment\n",
    "- `Random` to generate random numbers\n",
    "- `Deque` to record cumulative reward over multiple episodes\n",
    "- `MatPlotlib` to generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "oU8zRXv8QHlm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import or_gym\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from mlxtend.plotting import scatterplotmatrix\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fz-X3HTQueX"
   },
   "source": [
    "## Part 1: Explore Knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Task 1:** \n",
    "- Create an instance of the environment\n",
    "- Print and plot the state and action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mh9jBR_cQ5_a"
   },
   "outputs": [],
   "source": [
    "env = or_gym.make(\"Knapsack-v2\") # Create an  instance of the environment \n",
    "env.mask = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PdZVucK_jMf",
    "outputId": "c1aff157-3aa7-46c8-f368-0cc5de2af402",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space 200\n",
      "State space [[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69   0]\n",
      " [  3   5   9   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   8   3   5   6   4   6   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   5   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   3   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   1   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   7   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n"
     ]
    }
   ],
   "source": [
    "state_space = env.reset()#env.observation_space.n#Get number of states in an environment \n",
    "action_space = env.action_space.n#env.action_space.n#Get number of actions in an environment \n",
    "print('Action space', action_space)\n",
    "print('State space', state_space)\n",
    "#0: list of item weights\n",
    "#1: list of item values\n",
    "#2: list of item limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of the state space\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15, 5))\n",
    "\n",
    "ax1.hist(state_space[0])\n",
    "ax1.set_title(\"Items weight\")\n",
    "\n",
    "ax2.hist(state_space[1])\n",
    "ax2.set_title(\"Items value\")\n",
    "\n",
    "ax3.hist(state_space[2])\n",
    "ax3.set_title(\"Items limit\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scatterplotmatrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3fd0018ab5fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_space\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_space\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_space\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscatterplotmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Items weights\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Items value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Items limit\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scatterplotmatrix' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.array([state_space[0], state_space[1], state_space[2]]).T\n",
    "scatterplotmatrix(X, figsize=(15, 7), names = [\"Items weights\", \"Items value\", \"Items limit\"])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:**\n",
    "- Sample an action from the environment.\n",
    "- Call the step function and inspect the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "action = env.action_space.sample()# sample an action from the env instance\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  5,  62,  68,   9,  14,  21,  99,  76,  50,  75,   1,  27,  79,\n",
       "          80,  81,  84,  51,  41,  35,  34,  28,  56,  31,  97,  80,  11,\n",
       "          67,  75,  34,  39,  59,  76,  26,  69,  69,  63,  49,  51,  79,\n",
       "          98,   2,  66,  62,  13,   7,  11,  27,  92,  67,   5,  32,  89,\n",
       "          31,  18,  18,  85,  56,  57,  40,  82,  15,  18,  48,  59,  73,\n",
       "           7,  74,  43,  26,  30,  72,   6,  95,  92,  74,  54,  10,  71,\n",
       "           5,  48,  83,  46,   3,   4,  12,  29,  78,   2,  48,  37,  77,\n",
       "          14,  30,  40,  16,  79,  25,  74,  64,  63,  85,  26,  41,  31,\n",
       "          79,  88,  31,  26,  68,  18,  31,  62,  55,  60,  16,   5,  99,\n",
       "          34,  60,   8,  42,  33,  10,  80,  29,  93,   4,  26,  71,   6,\n",
       "          65,   9,  18,  79,  83,  69,  64,  90,  63,  55,   3,  76,  27,\n",
       "          57,  15,  72,  22,  85,  18,  78,  39,  36,  90,  46,  38,  60,\n",
       "          61,  37,   8,  57,  56,  54,  73,  51,  98,  35,  15,  54,  26,\n",
       "           6,  60,  14,  66,  31,  40,  24,  11,  66,  56,  70,  22,  71,\n",
       "          50,  95,  22,  72,  82,  57,  99,  70,  86,  19,  28,  95,  20,\n",
       "          85,  57,  65,  60,  51, 200],\n",
       "        [ 73,  90,  22,  49,  74,  20,  89,  27,   2,  81,   0,  80,  10,\n",
       "          14,  50,  83,  81,  76,  20,  52,  81,   6,  55,  49,  68,  74,\n",
       "          54,  79,  69,  21,  58,  39,  82,  67,   5,  41,  17,  68,  12,\n",
       "           3,  70,  27,  97,  28,  38,  68,  23,  26,  36,  77,  11,  35,\n",
       "          65,  49,  27,  70,  82,  30,  31,  12,  86,  21,  10,  12,  71,\n",
       "          88,   4,  99,  92,   2,  28,  56,   8,  71,  34,  84,   3,  67,\n",
       "          14,  11,  24,  28,  52,  30,  72,  14,  14,  71,  17,  67,   5,\n",
       "          64,  50,  25,  96,  48,  68,  90,  96,  97,  62,  27,  26,  34,\n",
       "          25,  84,  43,  96,  77,  52,  85,  79,  17,  79,  81,  77,  82,\n",
       "          26,  22,   4,  78,  81,  58,  18,  63,   2,  92,  35,  84,  27,\n",
       "          97,  75,  30,  98,  39,  87,  81,  62,  40,  77,  46,   7,  72,\n",
       "          61,  44,  32,  81,   1,  91,  98,  93,  35,  97,  51,  24,  40,\n",
       "          30,  55,  56,  66,  88,  94,  38,  14,  76,   1,   0,  27,  89,\n",
       "          86,  59,  47,  16,  44,  19,  78,  28,  77,  66,  99,   7,  29,\n",
       "          94,  22,   7,  18,  63,  35,  27,  99,  73,  84,  55,  77,   5,\n",
       "          79,  11,  82,  24,  69,  22],\n",
       "        [  3,   5,   9,   4,   2,   4,   7,   6,   3,   1,   2,   3,   9,\n",
       "           6,   3,   8,   8,   4,   8,   7,   8,   3,   5,   6,   4,   6,\n",
       "           4,   7,   6,   1,   9,   8,   3,   6,   5,   5,   5,   6,   9,\n",
       "           3,   9,   5,   6,   2,   9,   8,   6,   5,   9,   6,   3,   3,\n",
       "           1,   6,   2,   9,   4,   3,   1,   3,   2,   3,   9,   1,   5,\n",
       "           2,   2,   3,   5,   4,   5,   9,   1,   9,   2,   5,   9,   1,\n",
       "           7,   5,   7,   2,   6,   9,   3,   2,   9,   5,   4,   1,   5,\n",
       "           4,   8,   6,   6,   9,   7,   4,   6,   4,   3,   7,   4,   5,\n",
       "           8,   4,   3,   9,   9,   6,   9,   3,   3,   6,   9,   5,   4,\n",
       "           7,   8,   1,   7,   9,   9,   1,   8,   1,   3,   1,   2,   1,\n",
       "           8,   4,   2,   1,   7,   5,   5,   2,   3,   7,   7,   6,   6,\n",
       "           1,   8,   2,   8,   1,   6,   1,   3,   7,   5,   7,   7,   1,\n",
       "           7,   1,   3,   7,   9,   8,   9,   1,   9,   8,   8,   7,   9,\n",
       "           6,   3,   8,   2,   6,   2,   4,   5,   9,   9,   1,   3,   9,\n",
       "           7,   3,   2,   1,   2,   5,   5,   5,   5,   3,   4,   3,   4,\n",
       "           1,   6,   7,   7,   2,   0]]),\n",
       " 7,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action)# call the step function of the env. and inspect quadruple of (state, reward, done, info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dQ6sZJR-39K"
   },
   "source": [
    "**Task 3:**\n",
    "- Randomly interact with the envrionment for two episodes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkS_hnft-3A2",
    "outputId": "448fa484-b06b-43a6-c4e5-650e0bef88ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE  0\n",
      "__________\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69  36]\n",
      " [  3   5   9   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   8   3   5   6   4   6   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   5   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   3   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   1   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   6   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 151 with a reward of 35\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69  47]\n",
      " [  3   5   9   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   8   3   5   6   4   5   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   5   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   3   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   1   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   6   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 25 with a reward of 74\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69  75]\n",
      " [  3   5   9   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   7   3   5   6   4   5   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   5   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   3   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   1   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   6   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 20 with a reward of 81\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69 155]\n",
      " [  3   5   9   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   7   3   5   6   4   5   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   5   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   3   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   0   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   6   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 123 with a reward of 18\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69 173]\n",
      " [  3   5   9   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   7   3   5   6   4   5   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   5   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   3   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   0   8   1\n",
      "    3   1   2   1   8   4   1   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   6   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 132 with a reward of 30\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69 173]\n",
      " [  3   5   9   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   7   3   5   6   4   5   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   5   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   3   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   0   8   1\n",
      "    3   1   2   1   8   4   1   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   6   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 138 with a reward of 0\n",
      "\n",
      "Item 138 exceeded the limit which has a weight of 63\n",
      "Total weight sack =\t 18\n",
      "Number of items =\t 5\n",
      "Total reward =\t 238\n",
      "\n",
      "EPISODE  1\n",
      "__________\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69   2]\n",
      " [  3   5   9   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   8   3   5   6   4   6   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   4   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   3   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   1   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   7   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 87 with a reward of 71\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69  87]\n",
      " [  3   5   9   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   8   3   5   6   4   6   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   4   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   2   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   1   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   7   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 100 with a reward of 62\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69 155]\n",
      " [  3   5   8   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   8   3   5   6   4   6   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   6   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   4   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   2   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   1   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   7   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 2 with a reward of 22\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69 182]\n",
      " [  3   5   8   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   8   3   5   6   4   6   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   5   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   4   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   2   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   1   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   7   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 46 with a reward of 23\n",
      "[[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "   35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "   49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "   18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "   95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "   77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "   68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "    4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "   15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "   73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "   22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "   60  51 200]\n",
      " [ 73  90  22  49  74  20  89  27   2  81   0  80  10  14  50  83  81  76\n",
      "   20  52  81   6  55  49  68  74  54  79  69  21  58  39  82  67   5  41\n",
      "   17  68  12   3  70  27  97  28  38  68  23  26  36  77  11  35  65  49\n",
      "   27  70  82  30  31  12  86  21  10  12  71  88   4  99  92   2  28  56\n",
      "    8  71  34  84   3  67  14  11  24  28  52  30  72  14  14  71  17  67\n",
      "    5  64  50  25  96  48  68  90  96  97  62  27  26  34  25  84  43  96\n",
      "   77  52  85  79  17  79  81  77  82  26  22   4  78  81  58  18  63   2\n",
      "   92  35  84  27  97  75  30  98  39  87  81  62  40  77  46   7  72  61\n",
      "   44  32  81   1  91  98  93  35  97  51  24  40  30  55  56  66  88  94\n",
      "   38  14  76   1   0  27  89  86  59  47  16  44  19  78  28  77  66  99\n",
      "    7  29  94  22   7  18  63  35  27  99  73  84  55  77   5  79  11  82\n",
      "   24  69 182]\n",
      " [  3   5   8   4   2   4   7   6   3   1   2   3   9   6   3   8   8   4\n",
      "    8   7   8   3   5   6   4   6   4   7   6   1   9   8   3   6   5   5\n",
      "    5   6   9   3   9   5   6   2   9   8   5   5   9   6   3   3   1   6\n",
      "    2   9   4   3   1   3   2   3   9   1   5   2   2   3   5   4   5   9\n",
      "    1   9   2   5   9   1   7   5   7   2   6   9   3   2   9   4   4   1\n",
      "    5   4   8   6   6   9   7   4   6   4   2   7   4   5   8   4   3   9\n",
      "    9   6   9   3   3   6   9   5   4   7   8   1   7   9   9   1   8   1\n",
      "    3   1   2   1   8   4   2   1   7   5   5   2   3   7   7   6   6   1\n",
      "    8   2   8   1   6   1   3   7   5   7   7   1   7   1   3   7   9   8\n",
      "    9   1   9   8   8   7   9   6   3   8   2   6   2   4   5   9   9   1\n",
      "    3   9   7   3   3   1   2   5   5   5   5   3   4   3   4   1   6   7\n",
      "    7   2   0]]\n",
      "Item 33 with a reward of 0\n",
      "\n",
      "Item 33 exceeded the limit which has a weight of 69\n",
      "Total weight sack =\t 27\n",
      "Number of items =\t 4\n",
      "Total reward =\t 178\n"
     ]
    }
   ],
   "source": [
    "for episode in range(2):\n",
    "    state = env.reset()# get the starting state from the env.\n",
    "    total_reward = 0; weight = 0; nr_items = 0\n",
    "    done = False\n",
    "    print(\"\\nEPISODE \", episode)\n",
    "    print(\"__________\")\n",
    "    for step in range(99): \n",
    "        action = env.action_space.sample() # is the index of the items list\n",
    "        new_state, reward, done, info = env.step(action) #give the action to environment to obtain reward, and next state, \n",
    "        print(new_state)\n",
    "        print(\"Item {} with a reward of {}\".format(action, reward))\n",
    "        if done: # if the goal state is reached or bag is full. \n",
    "            print(\"\\nItem {} exceeded the limit which has a weight of {}\".format(action, new_state[0][action])) # Chosen a item that exceeds the capacity\n",
    "            print(\"Total weight sack =\\t\", weight)\n",
    "            print(\"Number of items =\\t\", nr_items)\n",
    "            print(\"Total reward =\\t\", total_reward)         \n",
    "            \n",
    "            break\n",
    "        nr_items += 1\n",
    "        total_reward += reward\n",
    "        state = new_state\n",
    "        weight = state[0][action]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5  62  68   9  14  21  99  76  50  75   1  27  79  80  81  84  51  41\n",
      "  35  34  28  56  31  97  80  11  67  75  34  39  59  76  26  69  69  63\n",
      "  49  51  79  98   2  66  62  13   7  11  27  92  67   5  32  89  31  18\n",
      "  18  85  56  57  40  82  15  18  48  59  73   7  74  43  26  30  72   6\n",
      "  95  92  74  54  10  71   5  48  83  46   3   4  12  29  78   2  48  37\n",
      "  77  14  30  40  16  79  25  74  64  63  85  26  41  31  79  88  31  26\n",
      "  68  18  31  62  55  60  16   5  99  34  60   8  42  33  10  80  29  93\n",
      "   4  26  71   6  65   9  18  79  83  69  64  90  63  55   3  76  27  57\n",
      "  15  72  22  85  18  78  39  36  90  46  38  60  61  37   8  57  56  54\n",
      "  73  51  98  35  15  54  26   6  60  14  66  31  40  24  11  66  56  70\n",
      "  22  71  50  95  22  72  82  57  99  70  86  19  28  95  20  85  57  65\n",
      "  60  51 200] [73 90 22 49 74 20 89 27  2 81  0 80 10 14 50 83 81 76 20 52 81  6 55 49\n",
      " 68 74 54 79 69 21 58 39 82 67  5 41 17 68 12  3 70 27 97 28 38 68 23 26\n",
      " 36 77 11 35 65 49 27 70 82 30 31 12 86 21 10 12 71 88  4 99 92  2 28 56\n",
      "  8 71 34 84  3 67 14 11 24 28 52 30 72 14 14 71 17 67  5 64 50 25 96 48\n",
      " 68 90 96 97 62 27 26 34 25 84 43 96 77 52 85 79 17 79 81 77 82 26 22  4\n",
      " 78 81 58 18 63  2 92 35 84 27 97 75 30 98 39 87 81 62 40 77 46  7 72 61\n",
      " 44 32 81  1 91 98 93 35 97 51 24 40 30 55 56 66 88 94 38 14 76  1  0 27\n",
      " 89 86 59 47 16 44 19 78 28 77 66 99  7 29 94 22  7 18 63 35 27 99 73 84\n",
      " 55 77  5 79 11 82 24 69  0] [3 5 9 4 2 4 7 6 3 1 2 3 9 6 3 8 8 4 8 7 8 3 5 6 4 6 4 7 6 1 9 8 3 6 5 5 5\n",
      " 6 9 3 9 5 6 2 9 8 6 5 9 6 3 3 1 6 2 9 4 3 1 3 2 3 9 1 5 2 2 3 5 4 5 9 1 9\n",
      " 2 5 9 1 7 5 7 2 6 9 3 2 9 5 4 1 5 4 8 6 6 9 7 4 6 4 3 7 4 5 8 4 3 9 9 6 9\n",
      " 3 3 6 9 5 4 7 8 1 7 9 9 1 8 1 3 1 2 1 8 4 2 1 7 5 5 2 3 7 7 6 6 1 8 2 8 1\n",
      " 6 1 3 7 5 7 7 1 7 1 3 7 9 8 9 1 9 8 8 7 9 6 3 8 2 6 2 4 5 9 9 1 3 9 7 3 3\n",
      " 1 2 5 5 5 5 3 4 3 4 1 6 7 7 2 0]\n"
     ]
    }
   ],
   "source": [
    "x_weight = state_space[0]\n",
    "x_value = state_space[1]\n",
    "x_limit = state_space[2]\n",
    "print(x_weight, x_value, x_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(item_count=action_space):\n",
    "    input_weights = tf.keras.Input((item_count+1),3)\n",
    "    #input_prices = tf.keras.Input((item_count,))\n",
    "    #input_limits = tf.keras.Input((item_count,))\n",
    "    \n",
    "    #inputs_concat = tf.keras.layers.Concatenate()([input_weights, input_prices, input_limits])\n",
    "    \n",
    "    picks = tf.keras.layers.Dense((item_count+1) ** 2 + (item_count+1) * 2, activation=\"sigmoid\")(input_weights)\n",
    "    picks = tf.keras.layers.Dense(item_count+1, activation=\"sigmoid\")(picks)\n",
    "    model = tf.keras.Model(inputs=input_weights, outputs=picks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model_target = get_model()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 106 43\n",
      "1 57 30\n",
      "2 87 71\n",
      "3 66 4\n",
      "4 148 91\n",
      "5 85 0\n",
      "6 137 0\n",
      "7 6 0\n",
      "8 184 0\n",
      "9 133 0\n",
      "[43, 30, 71, 4, 91, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1,201] vs. [10] [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-0ed4a6106b47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mlog_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mpolicy_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdiscounted_rewards\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1232\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1234\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1573\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1574\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1575\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    528\u001b[0m   \"\"\"\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6237\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6238\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6239\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6241\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6896\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6897\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6898\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,201] vs. [10] [Op:Mul]"
     ]
    }
   ],
   "source": [
    "ACTION_SPACE = action_space\n",
    "EPISODES = 1\n",
    "STEPS = 10\n",
    "GAMMA=0.99\n",
    "RENDER=False\n",
    "\n",
    "#optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "\n",
    "all_rewards =[]\n",
    "best_rolling = -99999\n",
    "for episode in range(EPISODES):\n",
    "    done=False\n",
    "    state = env.reset()\n",
    "    lp1=[]\n",
    "    lp2=[]\n",
    "    lp3=[]\n",
    "    a=[]\n",
    "    r=[]\n",
    "    d=[]\n",
    "    s=[]\n",
    "\n",
    "    for step in range(STEPS):\n",
    "        if RENDER:\n",
    "            env.render()\n",
    "        #print(model(state))\n",
    "        log_prob_weight, log_prob_value, log_prob_limit = model(state)\n",
    "        \n",
    "        #log_prob = log_prob_weight *log_prob_value * log_prob_limit\n",
    "        #print(log_prob)\n",
    "        \n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        state,reward,done,i_ = env.step(action)\n",
    "        #print(state,r_,done,i_)\n",
    "        \n",
    "        lp1.append(log_prob_weight)\n",
    "        lp2.append(log_prob_value)\n",
    "        lp3.append(log_prob_limit)\n",
    "        \n",
    "        r.append(reward)\n",
    "        print(step, action, reward)\n",
    "        if done:\n",
    "            all_rewards.append(np.sum(r))\n",
    "            \n",
    "            #if episode%100 ==0:\n",
    "            #   print(f\"EPISODE {episode} SCORE: {np.sum(r)} roll{pd.Series(all_rewards).tail(100).mean()}\")\n",
    "            #    # RENDER = True\n",
    "            #   torch.save(model.state_dict(), 'outputs/last_params_cloud.ckpt')\n",
    "            #   if pd.Series(all_rewards).tail(100).mean()>best_rolling:\n",
    "            #       best_rolling = pd.Series(all_rewards).tail(100).mean()\n",
    "            #       print(\"saving...\")\n",
    "            #       torch.save(model.state_dict(), 'outputs/best_params_cloud.ckpt')\n",
    "            #break\n",
    " \n",
    "    print(r)\n",
    "    discounted_rewards = []\n",
    "\n",
    "    for t in range(len(r)):\n",
    "        Gt = 0 \n",
    "        pw = 0\n",
    "        for r_ in r[t:]:\n",
    "            Gt = Gt + GAMMA**pw * r_\n",
    "            pw = pw + 1\n",
    "        discounted_rewards.append(Gt)\n",
    "    \n",
    "    discounted_rewards = np.array(discounted_rewards)\n",
    "    #print(discounted_rewards)\n",
    "    \n",
    "    #discounted_rewards = torch.tensor(discounted_rewards,dtype=torch.float32,device=DEVICE)\n",
    "    discounted_rewards = (discounted_rewards - np.mean(discounted_rewards))/ (np.std(discounted_rewards))\n",
    "    #print(discounted_rewards)\n",
    "    \n",
    "    log_prob = tf.stack(lp)\n",
    "    policy_gradient = -log_prob*discounted_rewards\n",
    "\n",
    "    model.zero_grad()\n",
    "    policy_gradient.sum().backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEtXMldxQ7uw"
   },
   "source": [
    "## Part 2: Q-Table \n",
    "We will implement Q-learning algorithm to devise optimal policy for FrozenLake environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4**\n",
    "- Create Q-table with `state space` as rows and `action space` as columns.\n",
    "state =16  action=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noM2G-NsF6Z9",
    "outputId": "c181f6f0-b3da-45af-aad8-de9ab638618b"
   },
   "outputs": [],
   "source": [
    "qtable = np.zeros((len(state_space), action_space))\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcdaN_DbA3ES"
   },
   "source": [
    "## Part 3: The Q learning algorithm \n",
    "It is fine if you do not understand all the details at this point. Q-learning will be introduced in Lecture 3 of DRL part. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rh_0vS_dBPCY"
   },
   "source": [
    "Q learning is a off-policy algorithm. Meaning that the actions that are executed are different from the target actions that are used for learning. \n",
    "Epsilon-greedy policy  most likely selects the `greedy actions` but can select `random actions` too \n",
    "- Ensures explorations\n",
    "- Choose greedy action with 1-  (epsilon) \n",
    "- Choose random action with  (epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBiRANB2AH3c"
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Q, state, epsilon): \n",
    "      # Q:          : state-action pair\n",
    "      # State (int) : current state\n",
    "      # eps (float): epsilon\n",
    "    action = 0\n",
    "    if random.uniform(0, 1) > epsilon: #exploitation\n",
    "        action = np.argmax(Q[state,:])\n",
    "    else: #exploration \n",
    "        action = env.action_space.sample()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOB4TejJM4uA"
   },
   "source": [
    "\n",
    "The algorithm takes nine arguments:\n",
    "- `env`: This is an instance of an OpenAI Gym environment.\n",
    "- `total_episodes`: This is the number of episodes that are generated through agent-environment interaction.\n",
    "- `max_step`: This is the max number of interactions between agent and env. within a single episode.  \n",
    "- `epsilon`: This is to encourage exploration. Epsilon is decayed over time to discourage explortation and encourage exploitation once agent has explored different state. \n",
    "- `max_epsilon`: This is the maximum value of epsilon. \n",
    "- `min_epsilon`: This is the minimum value of epsilon. \n",
    "- `decay_rate`: This is the decay rate for epsilon. \n",
    "- `gamma`: This is the discount rate.  It must be a value between 0 and 1, inclusive (default value: `1`).\n",
    "- `plot_every`: This is additional argument to plot the cumulative reward against episodes. \n",
    "\n",
    "The algorithm returns as output:\n",
    "- `qtable`: This is an ndarray where `qtable[s][a]` is the estimated action value corresponding to state `s` and action `a`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5**\n",
    "- Fill the missing code to complete the Q-learning implementation.\n",
    "- Write a condition to break the loop as soon as agent receives a reward of 0.78 or higher in 100 consecutive episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cNXlxF6F4k1"
   },
   "outputs": [],
   "source": [
    "def q_learning(env, total_episodes, max_steps = 99, epsilon = 1.0, max_epsilon = 1.0, min_epsilon = 0.01, decay_rate = 0.005,  gamma=0.95, plot_every=100):\n",
    "    rewards = []   # List of rewards\n",
    "    tmp_scores = deque(maxlen=plot_every)     # deque for keeping track of scores\n",
    "    avg_scores = deque(maxlen=total_episodes)   # average scores over every plot_every episodes\n",
    "    for episode in range(total_episodes):\n",
    "        state = env.reset()#Reset the environment to the starting state \n",
    "        #step = 0 \n",
    "        done = False\n",
    "        total_rewards = 0 # collected reward within an episode\n",
    "        if episode % 100 == 0: #monitor progress\n",
    "            print(\"\\rEpisode {}/{}\".format(episode, total_episodes), end=\"\") \n",
    "        \n",
    "        for step in range(max_steps): \n",
    "            action = epsilon_greedy_policy(qtable, state, epsilon)# call the epsilon greedy policy to obtain the actions  \n",
    "            new_state, reward, done, info = env.step(action) #take the action and observe resulting reward and state. \n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            # qtable[new_state,:] : all the actions we can take from new state\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action]) #update the qtable. np.max(qtable[new_state, :] is greedy action used for learning!. \n",
    "\n",
    "            total_rewards += reward # sum the rewards collected within an episode\n",
    "            state = new_state # Our new state is state\n",
    "            if done == True: #done is true when agent fall into hole or reached the goal state\n",
    "                tmp_scores.append(total_rewards)  #for plot\n",
    "                break\n",
    "        if (episode % plot_every == 0): #for plot\n",
    "            avg_scores.append(np.mean(tmp_scores))\n",
    "            \n",
    "            #....  #break the loop as soon as agent obtain the reward of 0.78 or higher in 100 consective episodes. \n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) # Reduce epsilon value to encourage expoitation and discouage exlortation \n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "    # plot performance\n",
    "    plt.plot(np.linspace(0,total_episodes,len(avg_scores),endpoint=False), np.asarray(avg_scores))\n",
    "    plt.xlabel('Episode Number')\n",
    "    plt.ylabel('Average Reward (Over %d Episodes)' % plot_every)\n",
    "    plt.show()\n",
    "    # print best 100-episode performance\n",
    "    print(('Best Average Reward over %d Episodes: ' % plot_every), np.max(avg_scores))    \n",
    "    return qtable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEGeWKKsAu7X"
   },
   "source": [
    "## Part 4: Train the agent  \n",
    "Here comes the real part. \n",
    "- We will train our agent using Q-learning algorithm defined above.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6**\n",
    "- Call the Q-learning algorithm with appropriate hyperparameter setting. \n",
    "- Find the hyper-parameters configuration  to solve the environment in fewer than 5000 training episodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJhPxx7UAunE"
   },
   "outputs": [],
   "source": [
    "total_episodes = 20000       # Total episodes\n",
    "learning_rate = 0.2#7          # Learning rate\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1.0                 # Exploration rate\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.01            # Minimum exploration probability \n",
    "decay_rate = 0.005            # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "id": "lGABCf7TGHRH",
    "outputId": "98e11365-ca70-4d52-c189-f13e0b466829"
   },
   "outputs": [],
   "source": [
    "q_learning(env, total_episodes, epsilon = 1.0, gamma=0.95, plot_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "R5czk9qTBQIU"
   },
   "source": [
    "## Part 5: Action in Action! \n",
    "- After training, the agent has develop a Q-table can be used to play FrozenLake. The Q-table tells agent which action to take in each state. \n",
    "- Run the code below to see our agent playing FrozenLake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "Bt8UsREaBNkJ",
    "outputId": "8aa495fa-08e8-4044-e143-6d7c681a9817"
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "for episode in range(5):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    print(\"********************\")\n",
    "    print(\"EPISODE \", episode)\n",
    "    for step in range(max_steps):\n",
    "        action = np.argmax(qtable[state,:])# Take the action (index) with maximum expected future reward given that state\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            env.render()\n",
    "            if new_state == 15:\n",
    "                print(\"Goal \")\n",
    "            else:\n",
    "                print(\"Hole \")            \n",
    "            # We print the number of step it took.\n",
    "            print(\"Number of steps\", step)            \n",
    "            break\n",
    "        state = new_state\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RkMMK4kj5h74",
    "0fz-X3HTQueX",
    "JEtXMldxQ7uw",
    "rcdaN_DbA3ES",
    "WEGeWKKsAu7X",
    "R5czk9qTBQIU"
   ],
   "name": "Solving FrozenLake using Q-learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
