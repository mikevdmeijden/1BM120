Pytorch (NN)
A typical training procedure for a neural network is as follows:

Define the neural network that has some learnable parameters (or weights)
Iterate over a dataset of inputs
Process input through the network
Compute the loss (how far is the output from being correct)
Propagate gradients back into the network’s parameters
Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient
https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html


REINFORCE 

https://www.analyticsvidhya.com/blog/2020/11/reinforce-algorithm-taking-baby-steps-in-reinforcement-learning/

Initialize a Random Policy (a NN that takes the state as input and returns the probability of actions)
Use the policy to play N steps of the game — record action probabilities-from policy, reward-from environment, action — sampled by agent
Calculate the discounted reward for each step by backpropagation
Calculate expected reward G
Adjust weights of Policy (back-propagate error in NN) to increase G
Repeat from 2
(examples) 
https://github.com/kvsnoufal/reinforce/blob/main/train_lunarLander.py

PPO
https://arxiv.org/abs/1707.06347 (PDF)
https://github.com/openai/baselines/blob/master/baselines/ppo2/ppo2.py (Example)
Snap hier oprecht niet heel veel van. 